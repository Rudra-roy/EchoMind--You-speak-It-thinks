# EchoMind--You-speak-It2. Admin Panel & Dashboard ✅ COMPLETED
A web‑based admin interface lets authorized staff view, search, and filter user profiles, registration dates, and basic usage statistics. Admins can drill down into each user's full prompt‑and‑response history to monitor activity and troubleshoot issues.

**Implementation Details:**
- Backend: Express routes for admin authentication and user management
- CRUD operations: Create, read, update, delete users with role-based access control
- Dashboard statistics: Real-time user counts, activity metrics, and message type breakdown
- User management: Add users, delete users (with cascade deletion of conversations/messages), toggle user status
- Security: JWT-based authentication with admin-only middleware protection
- Frontend: AdminDashboard component with user management interface, search, filtering, and modal forms
- API endpoints: `/api/admin/login`, `/api/admin/users`, `/api/admin/dashboard`hinks

**Project10. Custom Prompt Template Management ✅ COMPLETED
Users can create, edit, and select from a library of prompt templates (e.g., "Explain Like I'm Five" or "Technical Deep‑Dive") to tailor the VLM's response style.

**Implementation Details:**
- Backend: Mongoose model for PromptTemplate with CRUD operations
- REST API endpoints for template management (create, read, update, delete, duplicate, use)
- Default system templates automatically initialized on server start
- Frontend: PromptTemplateSelector component with category filtering and search
- Integrated into ChatScreen with template selection button and display
- Template usage tracked and applied to all message types (text, image, voice)
- Secure authentication-based access to templates


11. Session Analytics Dashboardview**:
EchoMind is a mobile application built in React-native using a Model-View-Controller (MVC) architecture. It provides end users with a seamless interface to interact with a remote Vision‑Language Model (VLM) via image, voice, and text inputs. All heavy inference is offloaded to a backend server, ensuring a lightweight, responsive client.


Functional Requirements: 
1. User Accounts & Data Persistence
Users can register and log in with an email/password flow secured via JWT, ensuring personalized access. Each user’s queries and generated responses are stored in a MongoDB collection keyed to their profile, allowing seamless retrieval and history tracking.


2. Admin Panel & Dashboard
A web‑based admin interface lets authorized staff view, search, and filter user profiles, registration dates, and basic usage statistics. Admins can drill down into each user’s full prompt‑and‑response history to monitor activity and troubleshoot issues.


3. Image Captioning
With a tap, users capture or select a photo and receive an instant, concise caption generated by the VLM and displayed on their screen.


4. Image‑Based Q&A
After viewing a generated caption, users can submit follow‑up questions about the same image (e.g., “What’s on the table?”) and get precise, context-aware answers.


5. Voice Query Input
 By pressing and holding the mic button, users can record spoken queries which are transcribed using Automatic Speech Recognition (ASR) and sent to the backend VLM for processing. This enables hands-free, natural language input, ideal for accessibility and convenience.

6. Text-to-Speech (TTS) Response
 The app reads out VLM-generated replies using high-quality Text-to-Speech, allowing users to hear responses instead of reading them. This feature supports multitasking, accessibility, and more immersive interactions, especially for visually impaired or on-the-go users.


7. Unified Multi‑Modal Chat Interface
A single chat view lets users pivot seamlessly between typing text, uploading or snapping images, and sending voice clips within the same conversation thread.


8. Accessibility Description Generator
Users can toggle accessibility options such as text size enlargement, voice-over playback of responses, and dark/light mode switching for better visual comfort.


9. Offline Interaction Cache
The last 10 user interactions—regardless of mode—are stored locally on the device, allowing users to revisit past queries and responses even without server connectivity.


10. Custom Prompt Template Management
Users can create, edit, and select from a library of prompt templates (e.g., “Explain Like I’m Five” or “Technical Deep‑Dive”) to tailor the VLM’s response style.


11. Session Analytics Dashboard
Within the app, users have access to a dashboard showing counts of image, voice, and text queries, timestamps of interactions, and average server response times.

